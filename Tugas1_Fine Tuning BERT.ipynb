{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kx_Acxvo1nje",
        "outputId": "1aed791a-e271-4afb-9d14-7a90c8ac07b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.7 MB 7.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 51.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 54.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 116 kB 68.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 53.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 62.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 99 kB 11.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 70.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 238 kB 61.4 MB/s \n",
            "\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "### INSTALL DEPS QUIETLY\n",
        "!pip install -U -q tfds-nightly tf-models-official==2.7.0 \"tensorflow-text==2.8.*\" nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XgTpm9ZxoN9"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as text  # A dependency of the preprocessing model\n",
        "import tensorflow_addons as tfa\n",
        "from official.nlp import optimization\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from typing import List, Dict, Callable\n",
        "from typing_extensions import Literal\n",
        "\n",
        "nltk.download('all', quiet=True)\n",
        "\n",
        "stopword_list = set(stopwords.words('indonesian'))\n",
        "tf.get_logger().setLevel('ERROR')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sz6P5pK3ldxQ"
      },
      "outputs": [],
      "source": [
        "os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"] = \"UNCOMPRESSED\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpHWNs1nV0Zn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if os.environ.get('COLAB_TPU_ADDR', None):\n",
        "  cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "  tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "  strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "elif tf.config.list_physical_devices('GPU'):\n",
        "  strategy = tf.distribute.MirroredStrategy()\n",
        "else:\n",
        "  raise ValueError('Running on CPU is not recommended.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8_ctG55-uTX"
      },
      "outputs": [],
      "source": [
        "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3'\n",
        "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2elMBPzsvTB9"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def remove_stopwords(sentence: str) -> str:\n",
        "  tokens = word_tokenize(sentence)\n",
        "\n",
        "  return \" \".join([word for word in tokens if not word in stopword_list])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeHEYKXGqjAZ"
      },
      "outputs": [],
      "source": [
        "def make_bert_preprocess_model(sentence_features: List[str], seq_length = 128):\n",
        "  \"\"\"Returns Model mapping string features to BERT inputs.\n",
        "  \n",
        "  See: https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3#:~:text=seq_length%3D128.-,General%20usage,-For%20pairs%20of\n",
        "\n",
        "  Args:\n",
        "    sentence_features: a list with the names of string-valued features.\n",
        "    seq_length: an integer that defines the sequence length of BERT inputs.\n",
        "\n",
        "  Returns:\n",
        "    A Keras Model that can be called on a list or dict of string Tensors\n",
        "    (with the order or names, resp., given by sentence_features) and\n",
        "    returns a dict of tensors for input to BERT.\n",
        "  \"\"\"\n",
        "\n",
        "  text_inputs: List[tf.keras.layers.Input] = [\n",
        "    tf.keras.layers.Input(shape=(), dtype=tf.string, name=ft)\n",
        "    for ft in sentence_features\n",
        "  ]\n",
        "\n",
        "  # Tokenize the text to word pieces.\n",
        "  preprocessor = hub.load(tfhub_handle_preprocess)\n",
        "  tokenize = hub.KerasLayer(preprocessor.tokenize)\n",
        "  # tokenize() returns an int32 RaggedTensor of shape [batch_size, (words), (tokens_per_word)].\n",
        "  tokenized_inputs = [tokenize(s) for s in text_inputs]\n",
        "\n",
        "  # Pack inputs. The details (start/end token ids, dict of output tensors)\n",
        "  # are model-dependent, so this gets loaded from the SavedModel.\n",
        "  bert_pack_inputs = hub.KerasLayer(\n",
        "    preprocessor.bert_pack_inputs,\n",
        "    arguments=dict(seq_length=seq_length),\n",
        "    name='bert_pack_inputs'\n",
        "  )\n",
        "  model_inputs = bert_pack_inputs(tokenized_inputs)\n",
        "  return tf.keras.Model(text_inputs, model_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FFWVZ-prfSq"
      },
      "outputs": [],
      "source": [
        "def convert_dataframe_to_tensor(df: pd.DataFrame, column: str, dtype) -> tf.Tensor:\n",
        "  return tf.convert_to_tensor(df[column], dtype=dtype, name=column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zhR-SVwx4_J"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "def load_dataset_from_tfds(in_memory_ds: Dict[str, pd.DataFrame], split: Literal['train', 'split', 'validation'], batch_size: int,\n",
        "                           bert_preprocess_model: tf.keras.Model):\n",
        "  is_training = split == 'train'\n",
        "\n",
        "  df = in_memory_ds[split]\n",
        "  data_count = len(df)\n",
        "\n",
        "  \"\"\"\n",
        "  https://www.tensorflow.org/tutorials/load_data/pandas_dataframe\n",
        "  \"\"\"\n",
        "\n",
        "  dataset = tf.data.Dataset.from_tensor_slices({\n",
        "      'label': convert_dataframe_to_tensor(in_memory_ds[split], 'label', dtype=tf.int32),\n",
        "      'text_a': convert_dataframe_to_tensor(in_memory_ds[split], 'text_a', dtype=tf.string)\n",
        "  })\n",
        "\n",
        "  if is_training:\n",
        "    dataset = dataset.shuffle(data_count)\n",
        "    dataset = dataset.repeat()\n",
        "  if batch_size > 0:\n",
        "    dataset = dataset.batch(batch_size)\n",
        "  else:\n",
        "    dataset = dataset.batch(data_count)\n",
        "  dataset = dataset.map(lambda ex: (bert_preprocess_model(ex), ex['label']))\n",
        "  dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDNKfAXbDnJH"
      },
      "source": [
        "## Define your model\n",
        "\n",
        "You are now ready to define your model for sentence or sentence pair classification by feeding the preprocessed inputs through the BERT encoder and putting a linear classifier on top (or other arrangement of layers as you prefer), and using dropout for regularization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aksj743St9ga"
      },
      "outputs": [],
      "source": [
        "class Classifier(tf.keras.Model):\n",
        "  def __init__(self, num_classes: int):\n",
        "    super(Classifier, self).__init__(name=\"prediction\")\n",
        "    self.encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True)\n",
        "    self.dropout = tf.keras.layers.Dropout(0.1)\n",
        "    self.dense = tf.keras.layers.Dense(num_classes)\n",
        "\n",
        "  def call(self, preprocessed_text):\n",
        "    encoder_outputs = self.encoder(preprocessed_text)\n",
        "    pooled_output = encoder_outputs[\"pooled_output\"]\n",
        "    x = self.dropout(pooled_output)\n",
        "    x = self.dense(x)\n",
        "    return x\n",
        "\n",
        "def build_classifier_model(num_classes: int):\n",
        "  model = Classifier(num_classes)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhL__V2mwRNH"
      },
      "outputs": [],
      "source": [
        "train_dataset_pd = pd.read_csv('train.csv')\n",
        "train_dataset_pd['text_a'] = train_dataset_pd['text_a'].apply(remove_stopwords)\n",
        "train_dataset_pd.loc[train_dataset_pd['label'] == 'no', 'label'] = 0\n",
        "train_dataset_pd.loc[train_dataset_pd['label'] == 'yes', 'label'] = 1\n",
        "num_train = len(train_dataset_pd)\n",
        "\n",
        "validation_dataset_pd = pd.read_csv('dev.csv')\n",
        "validation_dataset_pd['text_a'] = validation_dataset_pd['text_a'].apply(remove_stopwords)\n",
        "validation_dataset_pd.loc[validation_dataset_pd['label'] == 'no', 'label'] = 0\n",
        "validation_dataset_pd.loc[validation_dataset_pd['label'] == 'yes', 'label'] = 1\n",
        "num_validation = len(validation_dataset_pd)\n",
        "\n",
        "test_dataset_pd = pd.read_csv('test.csv')\n",
        "test_dataset_pd['text_a'] = test_dataset_pd['text_a'].apply(remove_stopwords)\n",
        "test_dataset_pd.loc[test_dataset_pd['label'] == 'no', 'label'] = 0\n",
        "test_dataset_pd.loc[test_dataset_pd['label'] == 'yes', 'label'] = 1\n",
        "num_test = len(test_dataset_pd)\n",
        "\n",
        "sentence_features = ['text_a']\n",
        "labels_names = ['no', 'yes']\n",
        "num_classes = len(labels_names)\n",
        "\n",
        "in_memory_ds = {\n",
        "    'train': train_dataset_pd,\n",
        "    'validation': validation_dataset_pd,\n",
        "    'test': test_dataset_pd\n",
        "}\n",
        "\n",
        "bert_preprocess_model = make_bert_preprocess_model(sentence_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWPOZE-L3AgE"
      },
      "outputs": [],
      "source": [
        "def get_configuration(num_classes: int):\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "  metrics = [tfa.metrics.MatthewsCorrelationCoefficient(num_classes=num_classes)]\n",
        "\n",
        "  return metrics, loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiU5_ioh_fEr",
        "outputId": "e6f233b8-328c-4e1f-dc52-710fce8d3f34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine tuning https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3 model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:559: UserWarning: Input dict contained keys ['label'] which did not match any model input. They will be ignored by the model.\n",
            "  inputs = self._flatten_to_reference_inputs(inputs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "675/675 [==============================] - 648s 928ms/step - loss: 0.3759 - MatthewsCorrelationCoefficient: 0.0000e+00 - val_loss: 0.3501 - val_MatthewsCorrelationCoefficient: 0.0000e+00\n",
            "Epoch 2/3\n",
            "675/675 [==============================] - 627s 929ms/step - loss: 0.2477 - MatthewsCorrelationCoefficient: 0.0000e+00 - val_loss: 0.3424 - val_MatthewsCorrelationCoefficient: 0.0000e+00\n",
            "Epoch 3/3\n",
            "675/675 [==============================] - 627s 929ms/step - loss: 0.1672 - MatthewsCorrelationCoefficient: 0.0000e+00 - val_loss: 0.4723 - val_MatthewsCorrelationCoefficient: 0.0000e+00\n"
          ]
        }
      ],
      "source": [
        "epochs = 3\n",
        "batch_size = 32\n",
        "init_lr = 2e-5\n",
        "\n",
        "print(f'Fine tuning {tfhub_handle_encoder} model')\n",
        "\n",
        "with strategy.scope():\n",
        "  # metric have to be created inside the strategy scope\n",
        "  metrics, loss = get_configuration(num_classes)\n",
        "\n",
        "  train_dataset = load_dataset_from_tfds(\n",
        "      in_memory_ds, 'train', batch_size, bert_preprocess_model)\n",
        "\n",
        "  steps_per_epoch = num_train // batch_size\n",
        "  num_train_steps = steps_per_epoch * epochs\n",
        "  num_warmup_steps = num_train_steps // 10\n",
        "\n",
        "  validation_dataset = load_dataset_from_tfds(\n",
        "      in_memory_ds, 'validation', batch_size,\n",
        "      bert_preprocess_model)\n",
        "  validation_steps = num_validation // batch_size\n",
        "\n",
        "  classifier_model = build_classifier_model(num_classes)\n",
        "\n",
        "  optimizer = optimization.create_optimizer(\n",
        "      init_lr=init_lr,\n",
        "      num_train_steps=num_train_steps,\n",
        "      num_warmup_steps=num_warmup_steps,\n",
        "      optimizer_type='adamw')\n",
        "\n",
        "  classifier_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "\n",
        "  classifier_model.fit(\n",
        "      x=train_dataset,\n",
        "      validation_data=validation_dataset,\n",
        "      steps_per_epoch=steps_per_epoch,\n",
        "      epochs=epochs,\n",
        "      validation_steps=validation_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMYpfV6w5RXy",
        "outputId": "6c1d580a-646d-45d8-9c9c-b5e4fcceb4a3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 364). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "main_save_path = './my_models'\n",
        "saved_model_name = 'my_model'\n",
        "\n",
        "saved_model_path = os.path.join(main_save_path, saved_model_name)\n",
        "\n",
        "preprocess_inputs = bert_preprocess_model.inputs\n",
        "bert_encoder_inputs = bert_preprocess_model(preprocess_inputs)\n",
        "bert_outputs = classifier_model(bert_encoder_inputs)\n",
        "model_for_export = tf.keras.Model(preprocess_inputs, bert_outputs)\n",
        "\n",
        "# Save everything on the Colab host (even the variables from TPU memory)\n",
        "save_options = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n",
        "model_for_export.save(saved_model_path, include_optimizer=False,\n",
        "                      options=save_options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yl-CEcDDXzX"
      },
      "outputs": [],
      "source": [
        "def prepare(record):\n",
        "  model_inputs = [[record[ft]] for ft in sentence_features]\n",
        "  return model_inputs, record['label']\n",
        "\n",
        "\n",
        "def convert_bert_results(bert_result):\n",
        "  bert_result_class = tf.argmax(bert_result, axis=1)[0]\n",
        "\n",
        "  return bert_result_class.numpy()\n",
        "\n",
        "def print_metrics(true_positive: int, true_negative: int, false_positive: int, false_negative: int):\n",
        "  accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
        "  print('accuracy =', accuracy)\n",
        "  precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) != 0 else 0\n",
        "  print('precision =', precision)\n",
        "  recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) != 0 else 0\n",
        "  print('recall =', recall)\n",
        "  f1 = 2 * precision * recall / (precision + recall) if (precision + recall) != 0 else 0\n",
        "  print('f1 =', f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12VA4BcKuR7n"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dt-O94gcwbIi",
        "outputId": "c87cff26-c9b7-4347-d3c2-4ad416cca1d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy = 0.8453571428571428\n",
            "precision = 0.6508810572687225\n",
            "recall = 0.8359264497878359\n",
            "f1 = 0.7318885448916409\n"
          ]
        }
      ],
      "source": [
        "with tf.device('/job:localhost'):\n",
        "  reloaded_model = tf.saved_model.load(saved_model_path)\n",
        "  test_dataset = tf.data.Dataset.from_tensor_slices({\n",
        "      'label': convert_dataframe_to_tensor(in_memory_ds['test'], 'label', tf.int32),\n",
        "      'text_a': convert_dataframe_to_tensor(in_memory_ds['test'], 'text_a', tf.string)\n",
        "  })\n",
        "\n",
        "  true_positive = 0\n",
        "  true_negative = 0\n",
        "  false_positive = 0\n",
        "  false_negative = 0\n",
        "  for test_row, label in test_dataset.shuffle(num_test).map(prepare):\n",
        "    if len(sentence_features) == 1:\n",
        "      result = reloaded_model(test_row[0])\n",
        "    else:\n",
        "      result = reloaded_model(list(test_row))\n",
        "\n",
        "    classification = convert_bert_results(result)\n",
        "    if label == 0:\n",
        "      if classification == 0:\n",
        "        true_negative += 1\n",
        "      else:\n",
        "        false_positive += 1\n",
        "    else: # label == 1\n",
        "      if classification == 0:\n",
        "        false_negative += 1\n",
        "      else:\n",
        "        true_positive += 1\n",
        "\n",
        "  assert true_positive +  true_negative + false_positive + false_negative == num_test\n",
        "\n",
        "  print_metrics(\n",
        "    true_positive=true_positive,\n",
        "    true_negative=true_negative,\n",
        "    false_positive=false_positive,\n",
        "    false_negative=false_negative\n",
        "  )\n",
        "  "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}